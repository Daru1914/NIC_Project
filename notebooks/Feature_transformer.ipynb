{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "This notebook is created to code the first prototype of a feature Transformer: a preprocessing step where a number of functions are applied on the features to improve performance: a major aspect of feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "\n",
    "import random\n",
    "from sko.GA import GA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# a set of utility functions used in the features transformers\n",
    "\n",
    "def get_name(x:pd.Series):\n",
    "    try:\n",
    "        return x.values, x.name\n",
    "    except AttributeError:\n",
    "        print(\"the argument passed is not a pandas.Series\")\n",
    "        # in this case the variable is assumed to be numpy array\n",
    "        return x, \"feat\"\n",
    "\n",
    "def polynomial(x:pd.Series, degree) -> pd.DataFrame:\n",
    "    # the x parameter is expected to be either Pandas.Series\n",
    "    # or numpy array with only one column\n",
    "    # this function applies  polynomial transformation to x up to the given order\n",
    "    # print(f\"degree:  {degree}\")\n",
    "    \n",
    "    values, col_name = get_name(x)\n",
    "    data = values ** degree\n",
    "    return pd.DataFrame(data=data, columns = [f\"{col_name} - poly-{degree}\"])\n",
    "\n",
    "def square_root(x: pd.Series) -> pd.DataFrame:\n",
    "    # this function applies function g to every element of the iterable x where\n",
    "    # g = sign(x) sqrt(abs(x))\n",
    "    values, col_name = get_name(x)\n",
    "    # apply the function to the iterable\n",
    "    data = np.sign(values) * np.sqrt(np.abs(values))\n",
    "    return pd.DataFrame(data=data, columns=[f\"{col_name} - sqrt\"])\n",
    "\n",
    "def reciprocal(x: pd.Series) -> pd.DataFrame:\n",
    "    # this function applies function g to every element of the iterable x where\n",
    "    # g = sign(x) / (1 + abs(x))\n",
    "    values, col_name = get_name(x)\n",
    "    data = np.sign(values) / (1 + np.abs(values))\n",
    "    return pd.DataFrame(data=data, columns=[f\"{col_name} - reciprocal\"])\n",
    "\n",
    "def box_cox(x: pd.Series) -> pd.DataFrame:\n",
    "    # define the power transformer\n",
    "    pt = PowerTransformer(method='box-cox', standardize=False)\n",
    "    values, col_name = get_name(x)\n",
    "    # take into consideration that box_cox transformation can be solely applied to positive values\n",
    "    data = np.sign(values).reshape(-1, 1) * pt.fit_transform(np.abs(values).reshape(-1, 1))\n",
    "    return pd.DataFrame(data=data, columns=[f\"{col_name} - box-cox\"])\n",
    "\n",
    "def yeo_johnson(x:pd.Series)-> pd.DataFrame:\n",
    "    pt = PowerTransformer(method=\"yeo-johnson\", standardize=False)\n",
    "    values, col_name = get_name(x)\n",
    "    data = pt.fit_transform(values.reshape(-1, 1))\n",
    "    return pd.DataFrame(data=data, columns=[f\"{col_name} - yeo-johnson\"])\n",
    "\n",
    "def quantile_transformation(x:pd.Series) -> pd.DataFrame:\n",
    "    qt = QuantileTransformer(random_state=0)\n",
    "    values, col_name = get_name(x)\n",
    "    data = qt.fit_transform(values.reshape(-1, 1))\n",
    "    return pd.DataFrame(data=data, columns=[f\"{col_name} - quantile\"])\n",
    "\n",
    "def set_mapper(poly_degree):\n",
    "    # set the non-polynomial features\n",
    "    mapper = [lambda x: square_root(x),\n",
    "              lambda x: reciprocal(x),\n",
    "              lambda x: box_cox(x),\n",
    "              lambda x: yeo_johnson(x),\n",
    "                 lambda x: x]\n",
    "    # add polynomial transformations\n",
    "\n",
    "    mapper.extend([lambda x, i=i: polynomial(x, i) for i in range(2, poly_degree + 1)])\n",
    "\n",
    "    return mapper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the FeatureTransformer class applies a number of functions on the columns in order to improve the linear correlation between\n",
    "# the features and the target variables: linear relations are easily detected by machine learning models and can lead to significant\n",
    "# performance boost\n",
    "\n",
    "class FeatureTransformer:\n",
    "    no_poly = 4\n",
    "\n",
    "    def _set_data(self, df:pd.DataFrame, y: np.array):\n",
    "        self.data = df\n",
    "        self.y = y\n",
    "\n",
    "    def __init__(self, size_pop=50, max_iter=200, prob_mut=0.001, df: pd.DataFrame=None, y:np.array=None, \n",
    "                 poly_degree:int=5, target_names:list=None):\n",
    "        # make sure either both df and y are None or both are not None\n",
    "        if df is None != y is None:\n",
    "            raise ValueError(\"Make sure that that either both data and target fields are None, or none of them\")\n",
    "\n",
    "        # setting the data field only if the argument is explicitly passed\n",
    "        # having self.data /  self.y as None variables could lead to difficulties in tracking bugs\n",
    "\n",
    "        if df:\n",
    "            self.data = df\n",
    "            self.y = y\n",
    "\n",
    "        # create a dictionary of the possible transformations to apply on the columns of the dataframe\n",
    "        self.function_mapper = set_mapper(poly_degree)\n",
    "        if target_names is None:\n",
    "            self.target_names = ['y', 'target', 'dependent_variable']\n",
    "\n",
    "        # set the parameters for running GA\n",
    "        self.size_pop = size_pop\n",
    "        self.max_iter = max_iter\n",
    "        self.prob_mut = prob_mut\n",
    "\n",
    "        # define a field for the latest fitted transformations\n",
    "        self.fitted_x = None \n",
    "        \n",
    "    @classmethod\n",
    "    def _mutation_pattern(cls, value_function, mapper):\n",
    "        # if the function is among the first 4 values (non-polynomial)\n",
    "        # then map it to another non-polynomial function\n",
    "        num_functions = len(mapper)\n",
    "        # if the function is non-polynomial\n",
    "        if value_function < 4:\n",
    "            while True:\n",
    "                new_value = random.choices(list(range(4)), k=1)[0]\n",
    "                if new_value != value_function:\n",
    "                    return new_value\n",
    "\n",
    "        # a value that will determine whether to increment or decrement the degree of the polynomial function\n",
    "        increase_decrease_prob = random.random()\n",
    "        return 4 + ((value_function + (1 if increase_decrease_prob < 0.5 else -1)) % (num_functions - 4))\n",
    "\n",
    "    def _mutation_chromosome(self, chromosome):\n",
    "        chromosome_length = len(chromosome)\n",
    "        position_to_mutate = random.randint(0, chromosome_length - 1)\n",
    "        chromosome[position_to_mutate] = self._mutation_pattern(chromosome[position_to_mutate], self.function_mapper)\n",
    "        return chromosome\n",
    "\n",
    "    # the actual function that will be called by the ga algorithm to perform mutation\n",
    "    def _ga_mutation_function(self, algorithm):\n",
    "        # according to the library's code the population is saved in a Chrom field: 2d np.array of shape (self.size_pop, self.n_dim),\n",
    "        # iterate through the population\n",
    "        for i in range(algorithm.size_pop):\n",
    "            if np.random.rand() < algorithm.prob_mut:\n",
    "                algorithm.Chrom[i] = self._mutation_chromosome(algorithm.Chrom[i])\n",
    "        \n",
    "        return algorithm.Chrom\n",
    "\n",
    "\n",
    "    def _find_target_name(self):\n",
    "        for name in self.target_names:\n",
    "            if name not in self.data.columns:\n",
    "                target = name\n",
    "                return target\n",
    "        # reaching this part of the code means that all the possible names to denote the target column\n",
    "        # are present in the dataframe, then raise an error\n",
    "        raise ValueError(\"All possible target names are already in use!!!\\nPlease consider adding a new target name or\"\n",
    "                         \"\\nchanging the dataframe's column names\")\n",
    "\n",
    "    def _new_features(self, chromosome: np.array, df:pd.DataFrame=None):\n",
    "        if df is None:\n",
    "            df = self.data\n",
    "\n",
    "        if not isinstance(df, pd.DataFrame):\n",
    "            df = pd.DataFrame(data=df, columns=range(df.shape[1]))\n",
    "        \n",
    "        # the chromosome is assumed to be a numpy array of size : number of features of the data field\n",
    "        # iterate through the chromosome: each value maps to a function\n",
    "        # apply this function on the corresponding column\n",
    "        new_features = [self.function_mapper[int(value_function)](df[d]) for d, value_function in zip(df.columns, chromosome)]\n",
    "\n",
    "        # concatenate all the new features into a single dataframe\n",
    "        all_data =  pd.concat(new_features, axis=1, ignore_index=False)\n",
    "        \n",
    "        return all_data\n",
    "        \n",
    "    def _get_correlation(self, chromosome) -> pd.Series:\n",
    "        # get the new features from the chromosome\n",
    "        new_features = self._new_features(chromosome)\n",
    "        \n",
    "        # retrieve the target name\n",
    "        target_name = self._find_target_name()\n",
    "        \n",
    "        # add the target variable's values as a column to the \"new_features\" dataframe\n",
    "        new_features[target_name] = self.y.copy()\n",
    "        \n",
    "        # compute the correlation matrix (linear correlation)\n",
    "        linear_corr = np.abs(new_features.corr()[target_name])\n",
    "\n",
    "        # order the columns by their correlation to the target\n",
    "        linear_corr.sort_values(ascending=False, inplace=True)\n",
    "        linear_corr.drop('y', inplace=True)\n",
    "        return linear_corr\n",
    "\n",
    "    def _ga_function(self, chromosome: np.array):\n",
    "        linear_corr = self._get_correlation(chromosome)\n",
    "        # the score is the reverse of the average score of the best \"num_feats\" new features\n",
    "        return 1 / (linear_corr.mean())\n",
    "\n",
    "\n",
    "    def fit(self, df:pd.DataFrame, y: np.array):\n",
    "        # if the passed object is not a dataframe\n",
    "        # then it is assumed to be  a numpy array\n",
    "        num_feats = df.shape[1]\n",
    "\n",
    "        if not isinstance(df, pd.DataFrame):\n",
    "            df = pd.DataFrame(data=df, columns=range(num_feats))\n",
    "        \n",
    "        # set the data fields for later use\n",
    "        self._set_data(df, y)\n",
    "\n",
    "        # define a function object to pass to the Genetic algorithm\n",
    "        ga_function = lambda x: self._ga_function(x)\n",
    "\n",
    "        # define the lower and upper bounds for the chromosomes\n",
    "        lower_bound = np.zeros(num_feats)\n",
    "        upper_bound = np.full(shape=(num_feats, ), fill_value=len(self.function_mapper) - 1)\n",
    "        # define the precision so that values in chromosome objects are integers\n",
    "        precision = np.full(shape=(num_feats, ), fill_value=1)\n",
    "\n",
    "        # define a ga object\n",
    "        ga = GA(func=ga_function, n_dim=num_feats, size_pop=self.size_pop, max_iter=self.max_iter, prob_mut=self.prob_mut,\n",
    "                lb=lower_bound, ub=upper_bound, precision=precision)\n",
    "\n",
    "        # register the mutation operator\n",
    "        ga.register(operator_name='mutation', operator=lambda x: self._ga_mutation_function(x))\n",
    "\n",
    "        # run the algorithm\n",
    "        best_x, best_y = ga.run()\n",
    "\n",
    "        self.fitted_x = best_x\n",
    "        \n",
    "    def transform(self, df:pd.DataFrame) -> pd.DataFrame:\n",
    "        if self.fitted_x is None:\n",
    "            raise ValueError(\"The feature transformer is not fitted yet. Make sure to call FeatureTransformer.fit(X, y) beforehand\")    \n",
    "        \n",
    "        return self._new_features(self.fitted_x, df)\n",
    "    \n",
    "    def fit_transform(self, df: pd.DataFrame, y: np.array) -> pd.DataFrame:\n",
    "        self.fit(df, y)\n",
    "        return self.transform(df)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "for dataset 0: with no transformations\n",
      "\n",
      "model: Nearest Neighbors\n",
      "accuracy: 0.905\n",
      "\n",
      "model: Linear SVM\n",
      "accuracy: 0.8675\n",
      "\n",
      "model: RBF SVM\n",
      "accuracy: 0.918125\n",
      "\n",
      "model: Decision Tree\n",
      "accuracy: 0.908125\n",
      "\n",
      "model: Random Forest\n",
      "accuracy: 0.91875\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [4], line 87\u001b[0m\n\u001b[0;32m     81\u001b[0m X \u001b[39m=\u001b[39m StandardScaler()\u001b[39m.\u001b[39mfit_transform(X)\n\u001b[0;32m     83\u001b[0m X_train, X_test, y_train, y_test \u001b[39m=\u001b[39m train_test_split(\n\u001b[0;32m     84\u001b[0m     X, y, test_size\u001b[39m=\u001b[39m\u001b[39m0.4\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m\n\u001b[0;32m     85\u001b[0m )\n\u001b[1;32m---> 87\u001b[0m X_train \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39;49mfit_transform(X_train, y_train)\n\u001b[0;32m     88\u001b[0m X_test \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39mtransform(X_test)\n\u001b[0;32m     90\u001b[0m f\u001b[39m.\u001b[39mwrite(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn [3], line 161\u001b[0m, in \u001b[0;36mFeatureTransformer.fit_transform\u001b[1;34m(self, df, y)\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit_transform\u001b[39m(\u001b[39mself\u001b[39m, df: pd\u001b[39m.\u001b[39mDataFrame, y: np\u001b[39m.\u001b[39marray) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m pd\u001b[39m.\u001b[39mDataFrame:\n\u001b[1;32m--> 161\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(df, y)\n\u001b[0;32m    162\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform(df)\n",
      "Cell \u001b[1;32mIn [3], line 150\u001b[0m, in \u001b[0;36mFeatureTransformer.fit\u001b[1;34m(self, df, y)\u001b[0m\n\u001b[0;32m    147\u001b[0m ga\u001b[39m.\u001b[39mregister(operator_name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmutation\u001b[39m\u001b[39m'\u001b[39m, operator\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m x: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ga_mutation_function(x))\n\u001b[0;32m    149\u001b[0m \u001b[39m# run the algorithm\u001b[39;00m\n\u001b[1;32m--> 150\u001b[0m best_x, best_y \u001b[39m=\u001b[39m ga\u001b[39m.\u001b[39;49mrun()\n\u001b[0;32m    152\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfitted_x \u001b[39m=\u001b[39m best_x\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sko\\GA.py:82\u001b[0m, in \u001b[0;36mGeneticAlgorithmBase.run\u001b[1;34m(self, max_iter)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_iter):\n\u001b[0;32m     81\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mX \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchrom2x(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mChrom)\n\u001b[1;32m---> 82\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mY \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mx2y()\n\u001b[0;32m     83\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mranking()\n\u001b[0;32m     84\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mselection()\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sko\\GA.py:51\u001b[0m, in \u001b[0;36mGeneticAlgorithmBase.x2y\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mx2y\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m---> 51\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mY_raw \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunc(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mX)\n\u001b[0;32m     52\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhas_constraint:\n\u001b[0;32m     53\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mY \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mY_raw\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sko\\tools.py:113\u001b[0m, in \u001b[0;36mfunc_transformer.<locals>.func_transformed\u001b[1;34m(X)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfunc_transformed\u001b[39m(X):\n\u001b[1;32m--> 113\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39marray([func(x) \u001b[39mfor\u001b[39;49;00m x \u001b[39min\u001b[39;49;00m X])\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sko\\tools.py:113\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfunc_transformed\u001b[39m(X):\n\u001b[1;32m--> 113\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39marray([func(x) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m X])\n",
      "Cell \u001b[1;32mIn [3], line 134\u001b[0m, in \u001b[0;36mFeatureTransformer.fit.<locals>.<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_data(df, y)\n\u001b[0;32m    133\u001b[0m \u001b[39m# define a function object to pass to the Genetic algorithm\u001b[39;00m\n\u001b[1;32m--> 134\u001b[0m ga_function \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m x: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_ga_function(x)\n\u001b[0;32m    136\u001b[0m \u001b[39m# define the lower and upper bounds for the chromosomes\u001b[39;00m\n\u001b[0;32m    137\u001b[0m lower_bound \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros(num_feats)\n",
      "Cell \u001b[1;32mIn [3], line 117\u001b[0m, in \u001b[0;36mFeatureTransformer._ga_function\u001b[1;34m(self, chromosome)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_ga_function\u001b[39m(\u001b[39mself\u001b[39m, chromosome: np\u001b[39m.\u001b[39marray):\n\u001b[1;32m--> 117\u001b[0m     linear_corr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_correlation(chromosome)\n\u001b[0;32m    118\u001b[0m     \u001b[39m# the score is the reverse of the average score of the best \"num_feats\" new features\u001b[39;00m\n\u001b[0;32m    119\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m1\u001b[39m \u001b[39m/\u001b[39m (linear_corr\u001b[39m.\u001b[39mmean())\n",
      "Cell \u001b[1;32mIn [3], line 100\u001b[0m, in \u001b[0;36mFeatureTransformer._get_correlation\u001b[1;34m(self, chromosome)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_correlation\u001b[39m(\u001b[39mself\u001b[39m, chromosome) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m pd\u001b[39m.\u001b[39mSeries:\n\u001b[0;32m     99\u001b[0m     \u001b[39m# get the new features from the chromosome\u001b[39;00m\n\u001b[1;32m--> 100\u001b[0m     new_features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_new_features(chromosome)\n\u001b[0;32m    102\u001b[0m     \u001b[39m# retrieve the target name\u001b[39;00m\n\u001b[0;32m    103\u001b[0m     target_name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_find_target_name()\n",
      "Cell \u001b[1;32mIn [3], line 91\u001b[0m, in \u001b[0;36mFeatureTransformer._new_features\u001b[1;34m(self, chromosome, df)\u001b[0m\n\u001b[0;32m     86\u001b[0m     df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(data\u001b[39m=\u001b[39mdf, columns\u001b[39m=\u001b[39m\u001b[39mrange\u001b[39m(df\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]))\n\u001b[0;32m     88\u001b[0m \u001b[39m# the chromosome is assumed to be a numpy array of size : number of features of the data field\u001b[39;00m\n\u001b[0;32m     89\u001b[0m \u001b[39m# iterate through the chromosome: each value maps to a function\u001b[39;00m\n\u001b[0;32m     90\u001b[0m \u001b[39m# apply this function on the corresponding column\u001b[39;00m\n\u001b[1;32m---> 91\u001b[0m new_features \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_mapper[\u001b[39mint\u001b[39;49m(value_function)](df[d]) \u001b[39mfor\u001b[39;49;00m d, value_function \u001b[39min\u001b[39;49;00m \u001b[39mzip\u001b[39;49m(df\u001b[39m.\u001b[39;49mcolumns, chromosome)]\n\u001b[0;32m     93\u001b[0m \u001b[39m# concatenate all the new features into a single dataframe\u001b[39;00m\n\u001b[0;32m     94\u001b[0m all_data \u001b[39m=\u001b[39m  pd\u001b[39m.\u001b[39mconcat(new_features, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, ignore_index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn [3], line 91\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     86\u001b[0m     df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(data\u001b[39m=\u001b[39mdf, columns\u001b[39m=\u001b[39m\u001b[39mrange\u001b[39m(df\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]))\n\u001b[0;32m     88\u001b[0m \u001b[39m# the chromosome is assumed to be a numpy array of size : number of features of the data field\u001b[39;00m\n\u001b[0;32m     89\u001b[0m \u001b[39m# iterate through the chromosome: each value maps to a function\u001b[39;00m\n\u001b[0;32m     90\u001b[0m \u001b[39m# apply this function on the corresponding column\u001b[39;00m\n\u001b[1;32m---> 91\u001b[0m new_features \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_mapper[\u001b[39mint\u001b[39;49m(value_function)](df[d]) \u001b[39mfor\u001b[39;00m d, value_function \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(df\u001b[39m.\u001b[39mcolumns, chromosome)]\n\u001b[0;32m     93\u001b[0m \u001b[39m# concatenate all the new features into a single dataframe\u001b[39;00m\n\u001b[0;32m     94\u001b[0m all_data \u001b[39m=\u001b[39m  pd\u001b[39m.\u001b[39mconcat(new_features, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, ignore_index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn [2], line 61\u001b[0m, in \u001b[0;36mset_mapper.<locals>.<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mset_mapper\u001b[39m(poly_degree):\n\u001b[0;32m     57\u001b[0m     \u001b[39m# set the non-polynomial features\u001b[39;00m\n\u001b[0;32m     58\u001b[0m     mapper \u001b[39m=\u001b[39m [\u001b[39mlambda\u001b[39;00m x: square_root(x),\n\u001b[0;32m     59\u001b[0m               \u001b[39mlambda\u001b[39;00m x: reciprocal(x),\n\u001b[0;32m     60\u001b[0m               \u001b[39mlambda\u001b[39;00m x: box_cox(x),\n\u001b[1;32m---> 61\u001b[0m               \u001b[39mlambda\u001b[39;00m x: yeo_johnson(x),\n\u001b[0;32m     62\u001b[0m                  \u001b[39mlambda\u001b[39;00m x: x]\n\u001b[0;32m     63\u001b[0m     \u001b[39m# add polynomial transformations\u001b[39;00m\n\u001b[0;32m     65\u001b[0m     mapper\u001b[39m.\u001b[39mextend([\u001b[39mlambda\u001b[39;00m x, i\u001b[39m=\u001b[39mi: polynomial(x, i) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m2\u001b[39m, poly_degree \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m)])\n",
      "Cell \u001b[1;32mIn [2], line 47\u001b[0m, in \u001b[0;36myeo_johnson\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     45\u001b[0m pt \u001b[39m=\u001b[39m PowerTransformer(method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39myeo-johnson\u001b[39m\u001b[39m\"\u001b[39m, standardize\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m     46\u001b[0m values, col_name \u001b[39m=\u001b[39m get_name(x)\n\u001b[1;32m---> 47\u001b[0m data \u001b[39m=\u001b[39m pt\u001b[39m.\u001b[39;49mfit_transform(values\u001b[39m.\u001b[39;49mreshape(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, \u001b[39m1\u001b[39;49m))\n\u001b[0;32m     48\u001b[0m \u001b[39mreturn\u001b[39;00m pd\u001b[39m.\u001b[39mDataFrame(data\u001b[39m=\u001b[39mdata, columns\u001b[39m=\u001b[39m[\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mcol_name\u001b[39m}\u001b[39;00m\u001b[39m - yeo-johnson\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:3058\u001b[0m, in \u001b[0;36mPowerTransformer.fit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m   3041\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit_transform\u001b[39m(\u001b[39mself\u001b[39m, X, y\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m   3042\u001b[0m     \u001b[39m\"\"\"Fit `PowerTransformer` to `X`, then transform `X`.\u001b[39;00m\n\u001b[0;32m   3043\u001b[0m \n\u001b[0;32m   3044\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3056\u001b[0m \u001b[39m        Transformed data.\u001b[39;00m\n\u001b[0;32m   3057\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 3058\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X, y, force_transform\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:3071\u001b[0m, in \u001b[0;36mPowerTransformer._fit\u001b[1;34m(self, X, y, force_transform)\u001b[0m\n\u001b[0;32m   3066\u001b[0m optim_function \u001b[39m=\u001b[39m {\n\u001b[0;32m   3067\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mbox-cox\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_box_cox_optimize,\n\u001b[0;32m   3068\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39myeo-johnson\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_yeo_johnson_optimize,\n\u001b[0;32m   3069\u001b[0m }[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmethod]\n\u001b[0;32m   3070\u001b[0m \u001b[39mwith\u001b[39;00m np\u001b[39m.\u001b[39merrstate(invalid\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m):  \u001b[39m# hide NaN warnings\u001b[39;00m\n\u001b[1;32m-> 3071\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlambdas_ \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([optim_function(col) \u001b[39mfor\u001b[39;49;00m col \u001b[39min\u001b[39;49;00m X\u001b[39m.\u001b[39;49mT])\n\u001b[0;32m   3073\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstandardize \u001b[39mor\u001b[39;00m force_transform:\n\u001b[0;32m   3074\u001b[0m     transform_function \u001b[39m=\u001b[39m {\n\u001b[0;32m   3075\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mbox-cox\u001b[39m\u001b[39m\"\u001b[39m: boxcox,\n\u001b[0;32m   3076\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myeo-johnson\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_yeo_johnson_transform,\n\u001b[0;32m   3077\u001b[0m     }[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmethod]\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:3071\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   3066\u001b[0m optim_function \u001b[39m=\u001b[39m {\n\u001b[0;32m   3067\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mbox-cox\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_box_cox_optimize,\n\u001b[0;32m   3068\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39myeo-johnson\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_yeo_johnson_optimize,\n\u001b[0;32m   3069\u001b[0m }[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmethod]\n\u001b[0;32m   3070\u001b[0m \u001b[39mwith\u001b[39;00m np\u001b[39m.\u001b[39merrstate(invalid\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m):  \u001b[39m# hide NaN warnings\u001b[39;00m\n\u001b[1;32m-> 3071\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlambdas_ \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([optim_function(col) \u001b[39mfor\u001b[39;00m col \u001b[39min\u001b[39;00m X\u001b[39m.\u001b[39mT])\n\u001b[0;32m   3073\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstandardize \u001b[39mor\u001b[39;00m force_transform:\n\u001b[0;32m   3074\u001b[0m     transform_function \u001b[39m=\u001b[39m {\n\u001b[0;32m   3075\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mbox-cox\u001b[39m\u001b[39m\"\u001b[39m: boxcox,\n\u001b[0;32m   3076\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myeo-johnson\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_yeo_johnson_transform,\n\u001b[0;32m   3077\u001b[0m     }[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmethod]\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:3262\u001b[0m, in \u001b[0;36mPowerTransformer._yeo_johnson_optimize\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m   3260\u001b[0m x \u001b[39m=\u001b[39m x[\u001b[39m~\u001b[39mnp\u001b[39m.\u001b[39misnan(x)]\n\u001b[0;32m   3261\u001b[0m \u001b[39m# choosing bracket -2, 2 like for boxcox\u001b[39;00m\n\u001b[1;32m-> 3262\u001b[0m \u001b[39mreturn\u001b[39;00m optimize\u001b[39m.\u001b[39;49mbrent(_neg_log_likelihood, brack\u001b[39m=\u001b[39;49m(\u001b[39m-\u001b[39;49m\u001b[39m2\u001b[39;49m, \u001b[39m2\u001b[39;49m))\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\optimize\\_optimize.py:2461\u001b[0m, in \u001b[0;36mbrent\u001b[1;34m(func, args, brack, tol, full_output, maxiter)\u001b[0m\n\u001b[0;32m   2390\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   2391\u001b[0m \u001b[39mGiven a function of one variable and a possible bracket, return\u001b[39;00m\n\u001b[0;32m   2392\u001b[0m \u001b[39mthe local minimum of the function isolated to a fractional precision\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2457\u001b[0m \n\u001b[0;32m   2458\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   2459\u001b[0m options \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mxtol\u001b[39m\u001b[39m'\u001b[39m: tol,\n\u001b[0;32m   2460\u001b[0m            \u001b[39m'\u001b[39m\u001b[39mmaxiter\u001b[39m\u001b[39m'\u001b[39m: maxiter}\n\u001b[1;32m-> 2461\u001b[0m res \u001b[39m=\u001b[39m _minimize_scalar_brent(func, brack, args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49moptions)\n\u001b[0;32m   2462\u001b[0m \u001b[39mif\u001b[39;00m full_output:\n\u001b[0;32m   2463\u001b[0m     \u001b[39mreturn\u001b[39;00m res[\u001b[39m'\u001b[39m\u001b[39mx\u001b[39m\u001b[39m'\u001b[39m], res[\u001b[39m'\u001b[39m\u001b[39mfun\u001b[39m\u001b[39m'\u001b[39m], res[\u001b[39m'\u001b[39m\u001b[39mnit\u001b[39m\u001b[39m'\u001b[39m], res[\u001b[39m'\u001b[39m\u001b[39mnfev\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\optimize\\_optimize.py:2498\u001b[0m, in \u001b[0;36m_minimize_scalar_brent\u001b[1;34m(func, brack, args, xtol, maxiter, disp, **unknown_options)\u001b[0m\n\u001b[0;32m   2495\u001b[0m brent \u001b[39m=\u001b[39m Brent(func\u001b[39m=\u001b[39mfunc, args\u001b[39m=\u001b[39margs, tol\u001b[39m=\u001b[39mtol,\n\u001b[0;32m   2496\u001b[0m               full_output\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, maxiter\u001b[39m=\u001b[39mmaxiter, disp\u001b[39m=\u001b[39mdisp)\n\u001b[0;32m   2497\u001b[0m brent\u001b[39m.\u001b[39mset_bracket(brack)\n\u001b[1;32m-> 2498\u001b[0m brent\u001b[39m.\u001b[39;49moptimize()\n\u001b[0;32m   2499\u001b[0m x, fval, nit, nfev \u001b[39m=\u001b[39m brent\u001b[39m.\u001b[39mget_result(full_output\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m   2501\u001b[0m success \u001b[39m=\u001b[39m nit \u001b[39m<\u001b[39m maxiter \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m (np\u001b[39m.\u001b[39misnan(x) \u001b[39mor\u001b[39;00m np\u001b[39m.\u001b[39misnan(fval))\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\optimize\\_optimize.py:2341\u001b[0m, in \u001b[0;36mBrent.optimize\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2339\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2340\u001b[0m     u \u001b[39m=\u001b[39m x \u001b[39m+\u001b[39m rat\n\u001b[1;32m-> 2341\u001b[0m fu \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49m((u,) \u001b[39m+\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs))      \u001b[39m# calculate new output value\u001b[39;00m\n\u001b[0;32m   2342\u001b[0m funcalls \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   2344\u001b[0m \u001b[39mif\u001b[39;00m (fu \u001b[39m>\u001b[39m fx):                 \u001b[39m# if it's bigger than current\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:3244\u001b[0m, in \u001b[0;36mPowerTransformer._yeo_johnson_optimize.<locals>._neg_log_likelihood\u001b[1;34m(lmbda)\u001b[0m\n\u001b[0;32m   3241\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_neg_log_likelihood\u001b[39m(lmbda):\n\u001b[0;32m   3242\u001b[0m     \u001b[39m\"\"\"Return the negative log likelihood of the observed data x as a\u001b[39;00m\n\u001b[0;32m   3243\u001b[0m \u001b[39m    function of lambda.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 3244\u001b[0m     x_trans \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_yeo_johnson_transform(x, lmbda)\n\u001b[0;32m   3245\u001b[0m     n_samples \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[0;32m   3246\u001b[0m     x_trans_var \u001b[39m=\u001b[39m x_trans\u001b[39m.\u001b[39mvar()\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:3214\u001b[0m, in \u001b[0;36mPowerTransformer._yeo_johnson_transform\u001b[1;34m(self, x, lmbda)\u001b[0m\n\u001b[0;32m   3211\u001b[0m     out[pos] \u001b[39m=\u001b[39m (np\u001b[39m.\u001b[39mpower(x[pos] \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, lmbda) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m/\u001b[39m lmbda\n\u001b[0;32m   3213\u001b[0m \u001b[39m# when x < 0\u001b[39;00m\n\u001b[1;32m-> 3214\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mabs\u001b[39m(lmbda \u001b[39m-\u001b[39m \u001b[39m2\u001b[39m) \u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mspacing(\u001b[39m1.0\u001b[39m):\n\u001b[0;32m   3215\u001b[0m     out[\u001b[39m~\u001b[39mpos] \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m(np\u001b[39m.\u001b[39mpower(\u001b[39m-\u001b[39mx[\u001b[39m~\u001b[39mpos] \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m \u001b[39m-\u001b[39m lmbda) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m/\u001b[39m (\u001b[39m2\u001b[39m \u001b[39m-\u001b[39m lmbda)\n\u001b[0;32m   3216\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# lmbda == 2\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# testing the feature transformer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "names = [\n",
    "    \"Nearest Neighbors\",\n",
    "    \"Linear SVM\",\n",
    "    \"RBF SVM\",\n",
    "    # \"Gaussian Process\",\n",
    "    \"Decision Tree\",\n",
    "    \"Random Forest\",\n",
    "    # \"Neural Net\",\n",
    "    # \"AdaBoost\",\n",
    "    # \"Naive Bayes\",\n",
    "    # \"QDA\",\n",
    "]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    SVC(gamma=2, C=1),\n",
    "    # GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    # MLPClassifier(alpha=1, max_iter=1000),\n",
    "    # AdaBoostClassifier(),\n",
    "    # GaussianNB(),\n",
    "    # QuadraticDiscriminantAnalysis(),\n",
    "]\n",
    "\n",
    "X, y = make_classification(\n",
    "    n_samples=4000, n_features=2, n_redundant=0, n_informative=2, random_state=1, n_clusters_per_class=1\n",
    ")\n",
    "rng = np.random.RandomState(2)\n",
    "X += 2 * rng.uniform(size=X.shape)\n",
    "linearly_separable = (X, y)\n",
    "\n",
    "datasets = [\n",
    "    make_moons(n_samples=4000, noise=0.3, random_state=0),\n",
    "    make_circles(n_samples=4000, noise=0.2, factor=0.5, random_state=1),\n",
    "    linearly_separable,\n",
    "]\n",
    "\n",
    "with open('test_transformer.txt', 'a') as f:\n",
    "    for ds_cnt, ds in enumerate(datasets):\n",
    "        # preprocess dataset, split into training and test part\n",
    "        X, y = ds\n",
    "        X = StandardScaler().fit_transform(X)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.4, random_state=42\n",
    "        )\n",
    "        \n",
    "        f.write(\"\\n\\n\")\n",
    "        f.write(f\"for dataset {ds_cnt} :\\n\")\n",
    "        \n",
    "        print()\n",
    "        print(f\"for dataset {ds_cnt}: with no transformations\")\n",
    "        \n",
    "        for name, clf in zip(names, classifiers):\n",
    "            clf.fit(X_train, y_train)\n",
    "            score = clf.score(X_test, y_test)\n",
    "            f.write(\"\\n\\n\")\n",
    "            f.write(f\"model: {name}\\n\")\n",
    "            f.write(f\"accuracy: {score}\\n\")\n",
    "\n",
    "            print()\n",
    "            print(f\"model: {name}\")\n",
    "            print(f\"accuracy: {score}\")\n",
    "\n",
    "        # add feature transformations\n",
    "        # create the feature transformer\n",
    "        transformer = FeatureTransformer()\n",
    "        X, y = ds\n",
    "        X = StandardScaler().fit_transform(X)\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.4, random_state=42\n",
    "        )\n",
    "\n",
    "        X_train = transformer.fit_transform(X_train, y_train)\n",
    "        X_test = transformer.transform(X_test)\n",
    "        \n",
    "        f.write(\"\\n\\n\")\n",
    "        f.write(f\"for dataset {ds_cnt} with transformations:\\n\")\n",
    "\n",
    "        print()\n",
    "        print(f\"for dataset {ds_cnt} with transformations\")\n",
    "        for name, clf in zip(names, classifiers):\n",
    "            clf.fit(X_train, y_train)\n",
    "            score = clf.score(X_test, y_test)\n",
    "            f.write(\"\\n\\n\")\n",
    "            f.write(f\"model: {name}\\n\")\n",
    "            f.write(f\"accuracy: {score}\\n\")\n",
    "\n",
    "            print(\"\\n\")\n",
    "            print(f\"model: {name}\")\n",
    "            print(f\"accuracy: {score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # def _get_new_df(self, chromosome):\n",
    "    #     num_feats = self.data.shape[1]\n",
    "    #     new_features = self._new_features(chromosome)\n",
    "    #     target_var = self._find_target_name()\n",
    "\n",
    "    #     correlation = new_features.corr()[target_var]\n",
    "    #     correlation.sort_values(ascending=False, inplace=True)\n",
    "    #     # make sure to remove the 'target_variable' from the correlation\n",
    "    #     correlation.drop('y', inplace=True)\n",
    "    #     return new_features.loc[:, list(correlation.iloc[:num_feats].index)]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "de47f5c92c0ee6f12a59a5613ac5feff6aab19ddff207ba0b3964cced08c4ccc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
