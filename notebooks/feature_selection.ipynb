{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>name</th>\n",
       "      <th>code</th>\n",
       "      <th>year</th>\n",
       "      <th>pop_growth</th>\n",
       "      <th>rural_pop</th>\n",
       "      <th>agri_land</th>\n",
       "      <th>death_rate</th>\n",
       "      <th>life_exp_male</th>\n",
       "      <th>life_exp_female</th>\n",
       "      <th>...</th>\n",
       "      <th>gpd</th>\n",
       "      <th>inflation</th>\n",
       "      <th>grd_growth</th>\n",
       "      <th>gpd_growth_per_capita</th>\n",
       "      <th>oil_rents</th>\n",
       "      <th>col_rents</th>\n",
       "      <th>foreign_invest</th>\n",
       "      <th>purchasing_power</th>\n",
       "      <th>school_enrol</th>\n",
       "      <th>food_consumption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Unnamed: 0, name, code, year, pop_growth, rural_pop, agri_land, death_rate, life_exp_male, life_exp_female, fertelity_rate, young_a_d, old_a_d, moratality_rate, gpd, inflation, grd_growth, gpd_growth_per_capita, oil_rents, col_rents, foreign_invest, purchasing_power, school_enrol, food_consumption]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 24 columns]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import evopreprocess as evp\n",
    "import niapy.algorithms.basic as nia\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "dataset = pd.read_excel(\"../databases/final_dataset.xlsx\")\n",
    "dataset.head()\n",
    "\n",
    "dataset.loc[dataset['name'] == 'moldova']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty cell check: False\n",
      "year                       int64\n",
      "rural_pop                float64\n",
      "agri_land                float64\n",
      "death_rate               float64\n",
      "life_exp_male            float64\n",
      "life_exp_female          float64\n",
      "fertility_rate           float64\n",
      "young_a_d                float64\n",
      "old_a_d                  float64\n",
      "mortality_rate           float64\n",
      "gpd                      float64\n",
      "inflation                float64\n",
      "grd_growth               float64\n",
      "gpd_growth_per_capita    float64\n",
      "oil_rents                float64\n",
      "col_rents                float64\n",
      "foreign_invest           float64\n",
      "purchasing_power         float64\n",
      "school_enrol             float64\n",
      "food_consumption         float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "target = dataset.loc[:, 'pop_growth']\n",
    "\n",
    "dataset.drop(columns=['Unnamed: 0', 'name', 'code', 'pop_growth'], inplace=True)\n",
    "dataset.rename(columns={'fertelity_rate': 'fertility_rate', 'moratality_rate': 'mortality_rate'}, inplace=True)\n",
    "\n",
    "print(f'Empty cell check: {np.isnan(dataset.values).any()}')\n",
    "\n",
    "print(dataset.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating regression models with k-fold cross-validation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ordinary Least Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1508704  0.08878651 0.10223447 0.07456343 0.15912567 0.12191264\n",
      " 0.10331104 0.18519325 0.15294851 0.15295555]\n",
      "[0.1508524  0.0887945  0.10239409 0.07462667 0.15922555 0.12204448\n",
      " 0.10347359 0.18518438 0.15293724 0.15297433]\n",
      "0.13639151526481155\n",
      "0.13644843785016242\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import get_scorer_names\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(dataset, target, train_size=60)\n",
    "\n",
    "# x1 = np.arange(100)\n",
    "# y1 = np.zeros(100)\n",
    "# for i in range(100):\n",
    "\n",
    "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "reg1 = linear_model.LinearRegression(fit_intercept=False, copy_X=True, positive=False)\n",
    "reg2 = linear_model.LinearRegression(fit_intercept=True, copy_X=True, positive=False)\n",
    "\n",
    "scores1 = abs(cross_val_score(reg1, dataset, target, scoring='neg_mean_squared_error', cv=cv, n_jobs=-1))\n",
    "scores2 = abs(cross_val_score(reg2, dataset, target, scoring='neg_mean_squared_error', cv=cv, n_jobs=-1))\n",
    "\n",
    "print(scores1)\n",
    "print(scores2)\n",
    "\n",
    "print(np.median(scores1))\n",
    "print(np.median(scores2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, difference is negligible with ot without intercept value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.09087325 0.10462387 0.22418435 0.07480145 0.1718964  0.20607426\n",
      " 0.20650918 0.13508841 0.12955173 0.08633357]\n",
      "0.1323200727859003\n",
      "[0.0907773  0.09867422 0.18450994 0.07427687 0.1719554  0.12209658\n",
      " 0.20541319 0.13508688 0.12650044 0.08560381]\n",
      "0.12429851385327337\n",
      "[0.09077525 0.09867375 0.184507   0.07427562 0.1719563  0.12209954\n",
      " 0.20542262 0.13508536 0.12649751 0.08560246]\n",
      "0.1242985257538297\n",
      "[0.09077321 0.09867329 0.18450406 0.07427438 0.1719572  0.1221025\n",
      " 0.20543205 0.13508384 0.12649458 0.08560112]\n",
      "0.12429853929575291\n",
      "[0.09077117 0.09867283 0.18450113 0.07427315 0.1719581  0.12210545\n",
      " 0.20544149 0.13508232 0.12649166 0.08559977]\n",
      "0.1242985544785864\n",
      "[0.09076913 0.09867237 0.18449819 0.07427191 0.171959   0.12210841\n",
      " 0.20545093 0.1350808  0.12648873 0.08559842]\n",
      "0.12429857130187719\n",
      "[0.0907671  0.09867191 0.18449526 0.07427067 0.17195991 0.12211137\n",
      " 0.20546037 0.13507929 0.12648581 0.08559708]\n",
      "0.12429858976517316\n",
      "[0.09076506 0.09867146 0.18449233 0.07426944 0.17196082 0.12211433\n",
      " 0.20546981 0.13507778 0.12648289 0.08559574]\n",
      "0.1242986098680191\n",
      "[0.09076304 0.09867101 0.1844894  0.0742682  0.17196173 0.1221173\n",
      " 0.20547925 0.13507628 0.12647997 0.0855944 ]\n",
      "0.12429863160996216\n",
      "[0.09076101 0.09867056 0.18448648 0.07426697 0.17196265 0.12212026\n",
      " 0.2054887  0.13507478 0.12647705 0.08559306]\n",
      "0.12429865499054829\n"
     ]
    }
   ],
   "source": [
    "cv = KFold(n_splits=10, random_state=2, shuffle=True)\n",
    "\n",
    "for alpha in np.arange(0, 1, 0.1):\n",
    "    reg = linear_model.Ridge(alpha)\n",
    "    scores = abs(cross_val_score(reg, dataset, target, scoring='neg_mean_squared_error', cv=cv, n_jobs=-1))\n",
    "    print(scores)\n",
    "    print(np.median(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With alpha > 0.1, Ridge Regression in general is more accurate than Linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.10909756 0.11473856 0.10639578 0.16180886 0.15154614 0.14340827\n",
      " 0.15388379 0.19628744 0.08179372 0.07529692]\n",
      "0.12907341130661618\n",
      "[0.17423527 0.17966181 0.14830682 0.23092919 0.17404721 0.18293267\n",
      " 0.25137133 0.28559081 0.10604141 0.09768816]\n",
      "0.1769485387179346\n",
      "[0.32744256 0.3686987  0.25301192 0.35781944 0.26919151 0.27868097\n",
      " 0.46617744 0.4631405  0.18359068 0.15959137]\n",
      "0.3030617657120962\n",
      "[0.57561463 0.68713344 0.43523344 0.55874974 0.44425057 0.44646135\n",
      " 0.81215881 0.7414766  0.31827309 0.26851665]\n",
      "0.5026055473811039\n",
      "[0.91840872 1.13465084 0.69473099 0.83348267 0.69892203 0.68545175\n",
      " 1.28890107 1.12059913 0.50994857 0.42455319]\n",
      "0.7662023547209158\n",
      "[1.03572525 1.22582717 0.80991992 0.95690369 0.81647688 0.80602663\n",
      " 1.36731111 1.22114917 0.62188432 0.52925492]\n",
      "0.886690287155528\n",
      "[1.0461863  1.23939752 0.81234957 0.9623745  0.81992738 0.81130402\n",
      " 1.3809424  1.2327337  0.62473716 0.53506092]\n",
      "0.8911509383369666\n",
      "[1.05704138 1.252582   0.81573343 0.96895215 0.82388553 0.81682906\n",
      " 1.39537135 1.24455728 0.62794006 0.54114221]\n",
      "0.8964188416715322\n",
      "[1.06914756 1.26692849 0.81992356 0.97668726 0.82895112 0.82254746\n",
      " 1.41036492 1.25771443 0.63204016 0.54718961]\n",
      "0.9028191911685963\n",
      "[1.08203961 1.28243701 0.82485275 0.98522995 0.83484615 0.82930013\n",
      " 1.42615648 1.27224186 0.63698807 0.55391762]\n",
      "0.9100380466083065\n"
     ]
    }
   ],
   "source": [
    "cv = KFold(n_splits=10, random_state=3, shuffle=True)\n",
    "\n",
    "for alpha in np.arange(0, 1, 0.1):\n",
    "    reg = linear_model.Lasso(alpha)\n",
    "    scores = abs(cross_val_score(reg, dataset, target, scoring='neg_mean_squared_error', cv=cv, n_jobs=-1))\n",
    "    print(scores)\n",
    "    print(np.median(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results show that Lasso Regression would be a terrible choice for our dataset, no matter the alpha score.\n",
    "\n",
    "#### Multi-Task Lasso Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\nAll the 10 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n10 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 2476, in fit\n    raise ValueError(\"For mono-task outputs, use %s\" % model_str)\nValueError: For mono-task outputs, use ElasticNet\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [127], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m alpha \u001b[39min\u001b[39;00m np\u001b[39m.\u001b[39marange(\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m0.1\u001b[39m):\n\u001b[0;32m      4\u001b[0m     reg \u001b[39m=\u001b[39m linear_model\u001b[39m.\u001b[39mMultiTaskLasso(alpha)\n\u001b[1;32m----> 5\u001b[0m     scores \u001b[39m=\u001b[39m \u001b[39mabs\u001b[39m(cross_val_score(reg, dataset, target, scoring\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mneg_mean_squared_error\u001b[39;49m\u001b[39m'\u001b[39;49m, cv\u001b[39m=\u001b[39;49mcv, n_jobs\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m))\n\u001b[0;32m      6\u001b[0m     \u001b[39mprint\u001b[39m(scores)\n\u001b[0;32m      7\u001b[0m     \u001b[39mprint\u001b[39m(np\u001b[39m.\u001b[39mmedian(scores))\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:515\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[39m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    513\u001b[0m scorer \u001b[39m=\u001b[39m check_scoring(estimator, scoring\u001b[39m=\u001b[39mscoring)\n\u001b[1;32m--> 515\u001b[0m cv_results \u001b[39m=\u001b[39m cross_validate(\n\u001b[0;32m    516\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[0;32m    517\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[0;32m    518\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[0;32m    519\u001b[0m     groups\u001b[39m=\u001b[39;49mgroups,\n\u001b[0;32m    520\u001b[0m     scoring\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mscore\u001b[39;49m\u001b[39m\"\u001b[39;49m: scorer},\n\u001b[0;32m    521\u001b[0m     cv\u001b[39m=\u001b[39;49mcv,\n\u001b[0;32m    522\u001b[0m     n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[0;32m    523\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m    524\u001b[0m     fit_params\u001b[39m=\u001b[39;49mfit_params,\n\u001b[0;32m    525\u001b[0m     pre_dispatch\u001b[39m=\u001b[39;49mpre_dispatch,\n\u001b[0;32m    526\u001b[0m     error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[0;32m    527\u001b[0m )\n\u001b[0;32m    528\u001b[0m \u001b[39mreturn\u001b[39;00m cv_results[\u001b[39m\"\u001b[39m\u001b[39mtest_score\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:285\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    265\u001b[0m parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39mverbose, pre_dispatch\u001b[39m=\u001b[39mpre_dispatch)\n\u001b[0;32m    266\u001b[0m results \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    267\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    268\u001b[0m         clone(estimator),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    282\u001b[0m     \u001b[39mfor\u001b[39;00m train, test \u001b[39min\u001b[39;00m cv\u001b[39m.\u001b[39msplit(X, y, groups)\n\u001b[0;32m    283\u001b[0m )\n\u001b[1;32m--> 285\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    287\u001b[0m \u001b[39m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[39m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[39m# the correct key.\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[39mif\u001b[39;00m callable(scoring):\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:367\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[39mif\u001b[39;00m num_failed_fits \u001b[39m==\u001b[39m num_fits:\n\u001b[0;32m    361\u001b[0m     all_fits_failed_message \u001b[39m=\u001b[39m (\n\u001b[0;32m    362\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mAll the \u001b[39m\u001b[39m{\u001b[39;00mnum_fits\u001b[39m}\u001b[39;00m\u001b[39m fits failed.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    363\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mIt is very likely that your model is misconfigured.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    364\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mYou can try to debug the error by setting error_score=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    365\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBelow are more details about the failures:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mfit_errors_summary\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    366\u001b[0m     )\n\u001b[1;32m--> 367\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    369\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    370\u001b[0m     some_fits_failed_message \u001b[39m=\u001b[39m (\n\u001b[0;32m    371\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mnum_failed_fits\u001b[39m}\u001b[39;00m\u001b[39m fits failed out of a total of \u001b[39m\u001b[39m{\u001b[39;00mnum_fits\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    372\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe score on these train-test partitions for these parameters\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBelow are more details about the failures:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mfit_errors_summary\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    377\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 10 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n10 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 2476, in fit\n    raise ValueError(\"For mono-task outputs, use %s\" % model_str)\nValueError: For mono-task outputs, use ElasticNet\n"
     ]
    }
   ],
   "source": [
    "cv = KFold(n_splits=10, random_state=3, shuffle=True)\n",
    "\n",
    "for alpha in np.arange(0, 1, 0.1):\n",
    "    reg = linear_model.MultiTaskLasso(alpha)\n",
    "    scores = abs(cross_val_score(reg, dataset, target, scoring='neg_mean_squared_error', cv=cv, n_jobs=-1))\n",
    "    print(scores)\n",
    "    print(np.median(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7137, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\evopreprocess\\feature_selection\\EvoFeatureSelection.py:164: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  features = stats.mode(features, axis=1, nan_policy='omit')[0].flatten()\n"
     ]
    }
   ],
   "source": [
    "GA_selection = evp.feature_selection.EvoFeatureSelection(\n",
    "    evaluator=DecisionTreeRegressor(max_depth=4),\n",
    "    optimizer=nia.GeneticAlgorithm,\n",
    "    random_seed=47,\n",
    "    n_runs=5,\n",
    "    n_folds=5,\n",
    "    n_jobs=None\n",
    ").fit_transform(dataset.values, target.values)\n",
    "\n",
    "print(GA_selection.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "de47f5c92c0ee6f12a59a5613ac5feff6aab19ddff207ba0b3964cced08c4ccc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
