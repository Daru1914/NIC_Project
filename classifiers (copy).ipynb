{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "This notebook is used to create tools to automate the training, tuning and saving of different sklearn models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary: Imports and constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# import tuning modules\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "\n",
    "# import metrics and scoring modules\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score, balanced_accuracy_score\n",
    "\n",
    "import math \n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import get_scorer_names\n",
    "score_function = {\"accuray\": accuracy_score, \"precision\": precision_score, \"recall\": recall_score, \n",
    "                  \"f1\": f1_score, \"balanced_accuracy\": balanced_accuracy_score}\n",
    "\n",
    "# constant used for cross validation\n",
    "CV = StratifiedKFold(n_splits=5, shuffle=True, random_state=11)\n",
    "# get_scorer_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# systemizing ML processes\n",
    "In this block we split the most common functionalities used in Machine learning in function block for re-usibility. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = make_classification(n_samples=4000, n_features=20, n_classes=3, random_state = 18, n_informative=8)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_model(model, params_grid, X_train, y_train, cv = None, scoring=None):\n",
    "    # scoring should be determined depending on the nature of the classification problem\n",
    "    if scoring is None:\n",
    "        # if the classification problem is binary\n",
    "        if len(np.unique(y_train)) == 2:\n",
    "            scoring='f1'\n",
    "        else:\n",
    "            scoring='balanced_accuracy'\n",
    "        \n",
    "    if cv is None:\n",
    "        cv = CV\n",
    "        \n",
    "    searcher = GridSearchCV(model, param_grid=params_grid, cv=cv, scoring=scoring, n_jobs=-1)\n",
    "    searcher.fit(X_train, y_train)\n",
    "    return searcher.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_tuned_model(tuned_model, X_train, X_test, y_train, y_test, train=True, metrics=['accuracy']):\n",
    "\n",
    "    if isinstance(metrics, str):\n",
    "        metrics = [metrics]\n",
    "        \n",
    "    # train the model\n",
    "    if train:\n",
    "        tuned_model.fit(X_train, y_train)\n",
    "        \n",
    "    # predict on the test dataset\n",
    "    y_pred = tuned_model.predict(X_test)\n",
    "    # evluate the model\n",
    "    scores = dict(list(zip(metrics, [score_function[m](y_test, y_pred) for m in metrics])))    \n",
    "    return tuned_model, scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(tuned_model, path):\n",
    "    with open(path, 'wb') as f:\n",
    "        pickle.dump(tuned_model, f)\n",
    "\n",
    "def load_model(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        return pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "def try_model(model, X, y, params_grid, save=True, save_path=None, test_size=0.2, tune_metric=None, test_metrics=['accuracy'], cv=None):\n",
    "    # the dataset passed is assumed to be ready to be processed\n",
    "    # all its features are numerical and all its missing values are imputed/discarded\n",
    "    \n",
    "    if save and save_path is None:\n",
    "        raise ValueError(\"Please pass a path to save the model or set the 'save' parameter to False\")\n",
    "    \n",
    "    # split the dataset into train and test datasets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size,random_state=11, stratify=y)\n",
    "    \n",
    "    # tune the model\n",
    "    tuned_model = tune_model(model, params_grid, X_train, y_train, cv=cv, scoring =tune_metric)\n",
    "    \n",
    "    # evluate teh tuned model\n",
    "    model, results = evaluate_tuned_model(tuned_model, X_train, y_train, X_test, y_test, test_metrics)    \n",
    "    # save the model to the passed path\n",
    "    if save:\n",
    "        save_model(tuned_model, save_path)\n",
    "     \n",
    "    return model, results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common Machine Learning models\n",
    "In this subsection, we customize the ML processes considered above for the most common Machine Learning models:\n",
    "* Logistic Regression\n",
    "* Linear SVM\n",
    "* DecisionTreeClassifier\n",
    "* RandomForestClassifier\n",
    "* XGBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22.71s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/ayhem18/Ayhem18/University/3rdYear1stSem/NIC/NIC_course_project/NIC_Project/classifiers (copy).ipynb Cell 14\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ayhem18/Ayhem18/University/3rdYear1stSem/NIC/NIC_course_project/NIC_Project/classifiers%20%28copy%29.ipynb#X16sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtry_LR\u001b[39m(X, y, lr_model\u001b[39m=\u001b[39mlr_basic, params_grid\u001b[39m=\u001b[39mLR_grid, save\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, save_path\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, test_size\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m, tune_metric\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, test_metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m], cv\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ayhem18/Ayhem18/University/3rdYear1stSem/NIC/NIC_course_project/NIC_Project/classifiers%20%28copy%29.ipynb#X16sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m try_model(lr_model, X, y, params_grid, save\u001b[39m=\u001b[39msave, save_path\u001b[39m=\u001b[39msave_path, test_size\u001b[39m=\u001b[39mtest_size, tune_metric\u001b[39m=\u001b[39mtune_metric, test_metrics\u001b[39m=\u001b[39mtest_metrics, cv\u001b[39m=\u001b[39mcv)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/ayhem18/Ayhem18/University/3rdYear1stSem/NIC/NIC_course_project/NIC_Project/classifiers%20%28copy%29.ipynb#X16sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m lr, results \u001b[39m=\u001b[39m try_LR(X, Y, save\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "\u001b[1;32m/home/ayhem18/Ayhem18/University/3rdYear1stSem/NIC/NIC_course_project/NIC_Project/classifiers (copy).ipynb Cell 14\u001b[0m in \u001b[0;36mtry_LR\u001b[0;34m(X, y, lr_model, params_grid, save, save_path, test_size, tune_metric, test_metrics, cv)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ayhem18/Ayhem18/University/3rdYear1stSem/NIC/NIC_course_project/NIC_Project/classifiers%20%28copy%29.ipynb#X16sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtry_LR\u001b[39m(X, y, lr_model\u001b[39m=\u001b[39mlr_basic, params_grid\u001b[39m=\u001b[39mLR_grid, save\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, save_path\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, test_size\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m, tune_metric\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, test_metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m], cv\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/ayhem18/Ayhem18/University/3rdYear1stSem/NIC/NIC_course_project/NIC_Project/classifiers%20%28copy%29.ipynb#X16sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m try_model(lr_model, X, y, params_grid, save\u001b[39m=\u001b[39;49msave, save_path\u001b[39m=\u001b[39;49msave_path, test_size\u001b[39m=\u001b[39;49mtest_size, tune_metric\u001b[39m=\u001b[39;49mtune_metric, test_metrics\u001b[39m=\u001b[39;49mtest_metrics, cv\u001b[39m=\u001b[39;49mcv)\n",
      "\u001b[1;32m/home/ayhem18/Ayhem18/University/3rdYear1stSem/NIC/NIC_course_project/NIC_Project/classifiers (copy).ipynb Cell 14\u001b[0m in \u001b[0;36mtry_model\u001b[0;34m(model, X, y, params_grid, save, save_path, test_size, tune_metric, test_metrics, cv)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ayhem18/Ayhem18/University/3rdYear1stSem/NIC/NIC_course_project/NIC_Project/classifiers%20%28copy%29.ipynb#X16sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m X_train, X_test, y_train, y_test \u001b[39m=\u001b[39m train_test_split(X, y, test_size\u001b[39m=\u001b[39mtest_size,random_state\u001b[39m=\u001b[39m\u001b[39m11\u001b[39m, stratify\u001b[39m=\u001b[39my)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ayhem18/Ayhem18/University/3rdYear1stSem/NIC/NIC_course_project/NIC_Project/classifiers%20%28copy%29.ipynb#X16sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# tune the model\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/ayhem18/Ayhem18/University/3rdYear1stSem/NIC/NIC_course_project/NIC_Project/classifiers%20%28copy%29.ipynb#X16sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m tuned_model \u001b[39m=\u001b[39m tune_model(model, params_grid, X_train, y_train, cv\u001b[39m=\u001b[39mcv, scoring \u001b[39m=\u001b[39mtune_metric)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ayhem18/Ayhem18/University/3rdYear1stSem/NIC/NIC_course_project/NIC_Project/classifiers%20%28copy%29.ipynb#X16sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m# evluate teh tuned model\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ayhem18/Ayhem18/University/3rdYear1stSem/NIC/NIC_course_project/NIC_Project/classifiers%20%28copy%29.ipynb#X16sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m model, results \u001b[39m=\u001b[39m evaluate_tuned_model(tuned_model, X_train, y_train, X_test, y_test, test_metrics)    \n",
      "\u001b[1;32m/home/ayhem18/Ayhem18/University/3rdYear1stSem/NIC/NIC_course_project/NIC_Project/classifiers (copy).ipynb Cell 14\u001b[0m in \u001b[0;36mtune_model\u001b[0;34m(model, params_grid, X_train, y_train, cv, scoring)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ayhem18/Ayhem18/University/3rdYear1stSem/NIC/NIC_course_project/NIC_Project/classifiers%20%28copy%29.ipynb#X16sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     cv \u001b[39m=\u001b[39m CV\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ayhem18/Ayhem18/University/3rdYear1stSem/NIC/NIC_course_project/NIC_Project/classifiers%20%28copy%29.ipynb#X16sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m searcher \u001b[39m=\u001b[39m GridSearchCV(model, param_grid\u001b[39m=\u001b[39mparams_grid, cv\u001b[39m=\u001b[39mcv, scoring\u001b[39m=\u001b[39mscoring, n_jobs\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/ayhem18/Ayhem18/University/3rdYear1stSem/NIC/NIC_course_project/NIC_Project/classifiers%20%28copy%29.ipynb#X16sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m searcher\u001b[39m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ayhem18/Ayhem18/University/3rdYear1stSem/NIC/NIC_course_project/NIC_Project/classifiers%20%28copy%29.ipynb#X16sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mreturn\u001b[39;00m searcher\u001b[39m.\u001b[39mbest_estimator_\n",
      "File \u001b[0;32m~/Ayhem18/DEV/Data_science/Towards_Data_Science/ds_env/lib/python3.10/site-packages/sklearn/model_selection/_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    869\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[1;32m    870\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    871\u001b[0m     )\n\u001b[1;32m    873\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[0;32m--> 875\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[1;32m    877\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    878\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    879\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Ayhem18/DEV/Data_science/Towards_Data_Science/ds_env/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1379\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1377\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1378\u001b[0m     \u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1379\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[0;32m~/Ayhem18/DEV/Data_science/Towards_Data_Science/ds_env/lib/python3.10/site-packages/sklearn/model_selection/_search.py:822\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    815\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[1;32m    816\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    817\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    818\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[1;32m    819\u001b[0m         )\n\u001b[1;32m    820\u001b[0m     )\n\u001b[0;32m--> 822\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    823\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    824\u001b[0m         clone(base_estimator),\n\u001b[1;32m    825\u001b[0m         X,\n\u001b[1;32m    826\u001b[0m         y,\n\u001b[1;32m    827\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[1;32m    828\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[1;32m    829\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[1;32m    830\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[1;32m    831\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[1;32m    832\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[1;32m    833\u001b[0m     )\n\u001b[1;32m    834\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[1;32m    835\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[1;32m    836\u001b[0m     )\n\u001b[1;32m    837\u001b[0m )\n\u001b[1;32m    839\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    840\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    841\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    842\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    843\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    844\u001b[0m     )\n",
      "File \u001b[0;32m~/Ayhem18/DEV/Data_science/Towards_Data_Science/ds_env/lib/python3.10/site-packages/joblib/parallel.py:1056\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1053\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1055\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1056\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[1;32m   1057\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1058\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[0;32m~/Ayhem18/DEV/Data_science/Towards_Data_Science/ds_env/lib/python3.10/site-packages/joblib/parallel.py:935\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    933\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    934\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m--> 935\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[1;32m    936\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    937\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[0;32m~/Ayhem18/DEV/Data_science/Towards_Data_Science/ds_env/lib/python3.10/site-packages/joblib/_parallel_backends.py:542\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[1;32m    540\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[1;32m    541\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 542\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m    543\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    544\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py:453\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[1;32m    451\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[0;32m--> 453\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_condition\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    456\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m/usr/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    321\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lr_basic = LogisticRegression(max_iter=5000)\n",
    "\n",
    "LR_grid = {\"C\": [0.1]}\n",
    "\n",
    "def try_LR(X, y, lr_model=lr_basic, params_grid=LR_grid, save=True, save_path=None, test_size=0.2, tune_metric=None, test_metrics=['accuracy'], cv=None):\n",
    "    return try_model(lr_model, X, y, params_grid, save=save, save_path=save_path, test_size=test_size, tune_metric=tune_metric, test_metrics=test_metrics, cv=cv)\n",
    "    \n",
    "lr, results = try_LR(X, Y, save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.5, 1.0, 1.5]\n",
    "}\n",
    "\n",
    "Log_clf = LogisticRegression()\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "grid = GridSearchCV(Log_clf, param_grid, refit = True, verbose = 1,n_jobs=-1, cv=cv)\n",
    "grid.fit(X_train, np.ravel(y_train, order='C'))\n",
    "print(grid.best_params_)\n",
    "y_pred = grid.predict(X_test)\n",
    "pickle.dump(grid.best_estimator_, open('log_reg_clf', 'wb'))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 15 folds for each of 30 candidates, totalling 450 fits\n",
      "{'max_depth': 10, 'min_samples_split': 4}\n",
      "0.855\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': range(10, 20),\n",
    "    'min_samples_split': [2, 3, 4]\n",
    "}\n",
    "\n",
    "tree=DecisionTreeClassifier()\n",
    "grid = GridSearchCV(tree, param_grid, refit = True, verbose = 1,n_jobs=-1, cv=cv)\n",
    "grid.fit(X_train, np.ravel(y_train, order='C'))\n",
    "print(grid.best_params_)\n",
    "y_pred = grid.predict(X_test)\n",
    "pickle.dump(grid.best_estimator_, open('dec_tree_clf', 'wb'))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 15 folds for each of 60 candidates, totalling 900 fits\n",
      "{'max_depth': 10, 'min_samples_split': 3, 'n_estimators': 100}\n",
      "0.93\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': range(8, 13),\n",
    "    'min_samples_split': [2, 3, 4],\n",
    "    'n_estimators': range(95, 111, 5)\n",
    "}\n",
    "\n",
    "\n",
    "forest=RandomForestClassifier()\n",
    "grid = GridSearchCV(forest, param_grid, refit = True, verbose = 1,n_jobs=-1, cv=cv)\n",
    "grid.fit(X_train, np.ravel(y_train, order='C'))\n",
    "print(grid.best_params_)\n",
    "y_pred = grid.predict(X_test)\n",
    "pickle.dump(grid.best_estimator_, open('rand_forest_clf', 'wb'))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 15 folds for each of 10 candidates, totalling 150 fits\n",
      "{'n_neighbors': 5}\n",
      "0.96\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "param_grid = {\n",
    "    'n_neighbors': range(5, 15)\n",
    "}\n",
    "\n",
    "model = KNeighborsClassifier()\n",
    "grid = GridSearchCV(model, param_grid, refit = True, verbose = 1,n_jobs=-1, cv=cv)\n",
    "grid.fit(X_train, np.ravel(y_train, order='C'))\n",
    "print(grid.best_params_)\n",
    "pickle.dump(grid.best_estimator_, open('knn_clf', 'wb'))\n",
    "y_pred = grid.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 15 folds for each of 18 candidates, totalling 270 fits\n",
      "{'C': 2.0, 'degree': 2, 'gamma': 'scale'}\n",
      "0.975\n"
     ]
    }
   ],
   "source": [
    "##SVM\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'degree': [2, 3, 4],\n",
    "    'gamma': ['scale', 'auto'],\n",
    "    'C': [0.5, 1.0, 2.0]\n",
    "}\n",
    "\n",
    "svmclassifier = SVC(kernel = 'rbf', random_state = 0)\n",
    "grid = GridSearchCV(svmclassifier, param_grid, refit = True, verbose = 1,n_jobs=-1, cv=cv)\n",
    "grid.fit(X_train, np.ravel(y_train, order='C'))\n",
    "print(grid.best_params_)\n",
    "pickle.dump(grid.best_estimator_, open('svm_clf', 'wb'))\n",
    "y_pred = grid.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 15 folds for each of 36 candidates, totalling 540 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/majed/my_partition/venv/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "360 fits failed out of a total of 540.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "180 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/majed/my_partition/venv/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/media/majed/my_partition/venv/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/media/majed/my_partition/venv/lib/python3.8/site-packages/xgboost/sklearn.py\", line 1516, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/media/majed/my_partition/venv/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/media/majed/my_partition/venv/lib/python3.8/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/media/majed/my_partition/venv/lib/python3.8/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/media/majed/my_partition/venv/lib/python3.8/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 2 for Parameter colsample_bylevel exceed bound [0,1]\n",
      "colsample_bylevel: Subsample ratio of columns, resample on each level.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "180 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/majed/my_partition/venv/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/media/majed/my_partition/venv/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/media/majed/my_partition/venv/lib/python3.8/site-packages/xgboost/sklearn.py\", line 1516, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/media/majed/my_partition/venv/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/media/majed/my_partition/venv/lib/python3.8/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/media/majed/my_partition/venv/lib/python3.8/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/media/majed/my_partition/venv/lib/python3.8/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 3 for Parameter colsample_bylevel exceed bound [0,1]\n",
      "colsample_bylevel: Subsample ratio of columns, resample on each level.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/media/majed/my_partition/venv/lib/python3.8/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.94041667 0.94125    0.94416667        nan        nan        nan\n",
      "        nan        nan        nan 0.94041667 0.94166667 0.94416667\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.94041667 0.94166667 0.94416667        nan        nan        nan\n",
      "        nan        nan        nan 0.94041667 0.94166667 0.94416667\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'base_score': 0.5, 'colsample_bylevel': 1, 'max_depth': 5}\n",
      "0.94\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "model = XGBClassifier(n_estimators=1000, max_depth=7, eta=0.1, subsample=0.7, colsample_bytree=0.8)\n",
    "\n",
    "param_grid = {\n",
    "    'base_score': [0.5, 1, 1.5, 2], \n",
    "    'max_depth': [3, 4, 5],\n",
    "    'colsample_bylevel': [1, 2, 3]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(model, param_grid, refit = True, verbose = 1,n_jobs=-1, cv=cv)\n",
    "grid.fit(X_train, np.ravel(y_train, order='C'))\n",
    "print(grid.best_params_)\n",
    "pickle.dump(grid.best_estimator_, open('xgb_clf', 'wb'))\n",
    "y_pred = grid.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds_env",
   "language": "python",
   "name": "ds_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "61791c176976d1dba33a88a8a27a02f11bc2b338382ecaeae452ea430b08bb75"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
