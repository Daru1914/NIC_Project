{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Imports and Loading the dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "dataset = pd.read_excel(os.path.join('databases', 'final_dataset.xlsx'), usecols=lambda x: 'Unnamed' not in x)\n",
    "dataset.drop(columns=['name', 'code'], inplace=True)\n",
    "y = dataset.pop('pop_growth')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def prepare_train_test(dataset, y, test_size=0.2, random_state=11):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(dataset, y, test_size=test_size, random_state=random_state)\n",
    "    X_train.reset_index(inplace=True, drop=True)\n",
    "    X_test.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    # for non year columns\n",
    "    standard_scaler = StandardScaler()\n",
    "    # for the year column\n",
    "    mm_scaler = MinMaxScaler()\n",
    "\n",
    "    X_train['year'] = mm_scaler.fit_transform(X_train.loc[:, ['year']]).reshape(-1, )\n",
    "    scaled_year = X_train.pop('year')\n",
    "\n",
    "    X_train = pd.DataFrame(data=standard_scaler.fit_transform(X_train), columns=X_train.columns)\n",
    "    X_train['year'] = scaled_year\n",
    "\n",
    "    X_test['year'] = mm_scaler.fit_transform(X_test.loc[:, ['year']]).reshape(-1, )\n",
    "    scaled_year = X_test.pop('year')\n",
    "\n",
    "    X_test = pd.DataFrame(data=standard_scaler.fit_transform(X_test), columns=X_test.columns)\n",
    "    X_test['year'] = scaled_year\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = prepare_train_test(dataset, y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Models and their parameters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "ridge_basic = Ridge(max_iter=5000)\n",
    "ridge_params = ridge_grid = {\"alpha\": np.logspace(0.001, 10, 20)}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mse': 0.17850173688651289}\n"
     ]
    }
   ],
   "source": [
    "### ridge\n",
    "from regressors import apply_model\n",
    "ridge_performance = apply_model(ridge_basic, X_train, X_test, y_train, y_test, ridge_params, save=False)\n",
    "print(ridge_performance[1])\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Our Pipeline"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "from multiColPSO import PsoMultiCol"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sko' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [33]\u001B[0m, in \u001B[0;36m<cell line: 2>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m pso \u001B[38;5;241m=\u001B[39m PsoMultiCol()\n\u001B[0;32m----> 2\u001B[0m new_dataset \u001B[38;5;241m=\u001B[39m \u001B[43mpso\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43meliminate_multicol\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      4\u001B[0m X_train, X_test, y_train, y_test \u001B[38;5;241m=\u001B[39m train_test_split(new_dataset, y, test_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.2\u001B[39m, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m11\u001B[39m)\n",
      "File \u001B[0;32m~/Ayhem18/University/3rdYear1stSem/NIC/NIC_course_project/NIC_Project/multiColPSO.py:182\u001B[0m, in \u001B[0;36mPsoMultiCol.eliminate_multicol\u001B[0;34m(self, df)\u001B[0m\n\u001B[1;32m    180\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mset_data(collinear_df)\n\u001B[1;32m    181\u001B[0m \u001B[38;5;66;03m# retrieve the best particle\u001B[39;00m\n\u001B[0;32m--> 182\u001B[0m best_x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_find_best_cluster\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    183\u001B[0m \u001B[38;5;66;03m# retrieve the new representation of the collinear features\u001B[39;00m\n\u001B[1;32m    184\u001B[0m new_collinear_df \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_new_df(best_x)\n",
      "File \u001B[0;32m~/Ayhem18/University/3rdYear1stSem/NIC/NIC_course_project/NIC_Project/multiColPSO.py:140\u001B[0m, in \u001B[0;36mPsoMultiCol._find_best_cluster\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    136\u001B[0m     \u001B[38;5;28;01mcontinue\u001B[39;00m\n\u001B[1;32m    138\u001B[0m last_num_clusters \u001B[38;5;241m=\u001B[39m num_clusters\n\u001B[0;32m--> 140\u001B[0m x, y \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_cluster_pso\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnum_clusters\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    141\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m y \u001B[38;5;241m<\u001B[39m best_score:\n\u001B[1;32m    142\u001B[0m     best_score \u001B[38;5;241m=\u001B[39m y\n",
      "File \u001B[0;32m~/Ayhem18/University/3rdYear1stSem/NIC/NIC_course_project/NIC_Project/multiColPSO.py:108\u001B[0m, in \u001B[0;36mPsoMultiCol._cluster_pso\u001B[0;34m(self, num_clusters)\u001B[0m\n\u001B[1;32m    105\u001B[0m lower_bound \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mzeros(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_feats)\n\u001B[1;32m    106\u001B[0m upper_bound \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mfull(shape\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_feats, fill_value\u001B[38;5;241m=\u001B[39mnum_clusters, dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfloat\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 108\u001B[0m pso \u001B[38;5;241m=\u001B[39m \u001B[43msko\u001B[49m\u001B[38;5;241m.\u001B[39mPSO\u001B[38;5;241m.\u001B[39mPSO(func\u001B[38;5;241m=\u001B[39mpso_function, n_dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_feats, pop\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m15\u001B[39m, max_iter\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmax_iter, lb\u001B[38;5;241m=\u001B[39mlower_bound,\n\u001B[1;32m    109\u001B[0m                   ub\u001B[38;5;241m=\u001B[39mupper_bound, c1\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1.5\u001B[39m, c2\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1.5\u001B[39m)\n\u001B[1;32m    110\u001B[0m pso\u001B[38;5;241m.\u001B[39mrun()\n\u001B[1;32m    112\u001B[0m x, y \u001B[38;5;241m=\u001B[39m pso\u001B[38;5;241m.\u001B[39mgbest_x, pso\u001B[38;5;241m.\u001B[39mgbest_y\n",
      "\u001B[0;31mNameError\u001B[0m: name 'sko' is not defined"
     ]
    }
   ],
   "source": [
    "pso = PsoMultiCol()\n",
    "new_dataset = pso.eliminate_multicol(dataset)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(new_dataset, y, test_size=0.2, random_state=11)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the same for the test dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Models and their parameters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "ridge_basic = Ridge(max_iter=5000)\n",
    "ridge_params = ridge_grid = {\"alpha\": np.logspace(0.001, 10, 20)}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### ridge\n",
    "from regressors import apply_model\n",
    "ridge_performance = apply_model(ridge_basic, X_train, X_test, y_train, y_test, ridge_params)\n",
    "print(ridge_performance)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import multiColPSO as mcp\n",
    "pso = mcp.PsoMultiCol()\n",
    "\n",
    "new_dataset = pso.eliminate_multicol(dataset)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(new_dataset, y, test_size=0.2, random_state=11)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds_env",
   "language": "python",
   "name": "ds_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
