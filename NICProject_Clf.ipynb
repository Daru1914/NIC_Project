{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.datasets import make_classification\n",
    "import numpy as np\n",
    "import pickle\n",
    "import warnings\n",
    "\n",
    "def fxn():\n",
    "    warnings.warn(\"deprecated\", DeprecationWarning)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    fxn()\n",
    "X, Y = make_classification(n_samples=1000, n_features=20, n_classes=4, random_state = 18,\n",
    "                                     class_sep=2.0, n_informative=8)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 15 folds for each of 3 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/majed/my_partition/venv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/media/majed/my_partition/venv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/media/majed/my_partition/venv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/media/majed/my_partition/venv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1.0}\n",
      "0.88\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import math \n",
    "import pickle\n",
    "\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.5, 1.0, 1.5]\n",
    "}\n",
    "\n",
    "Log_clf = LogisticRegression()\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "grid = GridSearchCV(Log_clf, param_grid, refit = True, verbose = 1,n_jobs=-1, cv=cv)\n",
    "grid.fit(X_train, np.ravel(y_train, order='C'))\n",
    "print(grid.best_params_)\n",
    "y_pred = grid.predict(X_test)\n",
    "pickle.dump(grid.best_estimator_, open('log_reg_clf', 'wb'))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 15 folds for each of 30 candidates, totalling 450 fits\n",
      "{'max_depth': 10, 'min_samples_split': 4}\n",
      "0.855\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': range(10, 20),\n",
    "    'min_samples_split': [2, 3, 4]\n",
    "}\n",
    "\n",
    "tree=DecisionTreeClassifier()\n",
    "grid = GridSearchCV(tree, param_grid, refit = True, verbose = 1,n_jobs=-1, cv=cv)\n",
    "grid.fit(X_train, np.ravel(y_train, order='C'))\n",
    "print(grid.best_params_)\n",
    "y_pred = grid.predict(X_test)\n",
    "pickle.dump(grid.best_estimator_, open('dec_tree_clf', 'wb'))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 15 folds for each of 60 candidates, totalling 900 fits\n",
      "{'max_depth': 10, 'min_samples_split': 3, 'n_estimators': 100}\n",
      "0.93\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': range(8, 13),\n",
    "    'min_samples_split': [2, 3, 4],\n",
    "    'n_estimators': range(95, 111, 5)\n",
    "}\n",
    "\n",
    "\n",
    "forest=RandomForestClassifier()\n",
    "grid = GridSearchCV(forest, param_grid, refit = True, verbose = 1,n_jobs=-1, cv=cv)\n",
    "grid.fit(X_train, np.ravel(y_train, order='C'))\n",
    "print(grid.best_params_)\n",
    "y_pred = grid.predict(X_test)\n",
    "pickle.dump(grid.best_estimator_, open('rand_forest_clf', 'wb'))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 15 folds for each of 10 candidates, totalling 150 fits\n",
      "{'n_neighbors': 5}\n",
      "0.96\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "param_grid = {\n",
    "    'n_neighbors': range(5, 15)\n",
    "}\n",
    "\n",
    "model = KNeighborsClassifier()\n",
    "grid = GridSearchCV(model, param_grid, refit = True, verbose = 1,n_jobs=-1, cv=cv)\n",
    "grid.fit(X_train, np.ravel(y_train, order='C'))\n",
    "print(grid.best_params_)\n",
    "pickle.dump(grid.best_estimator_, open('knn_clf', 'wb'))\n",
    "y_pred = grid.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 15 folds for each of 18 candidates, totalling 270 fits\n",
      "{'C': 2.0, 'degree': 2, 'gamma': 'scale'}\n",
      "0.975\n"
     ]
    }
   ],
   "source": [
    "##SVM\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'degree': [2, 3, 4],\n",
    "    'gamma': ['scale', 'auto'],\n",
    "    'C': [0.5, 1.0, 2.0]\n",
    "}\n",
    "\n",
    "svmclassifier = SVC(kernel = 'rbf', random_state = 0)\n",
    "grid = GridSearchCV(svmclassifier, param_grid, refit = True, verbose = 1,n_jobs=-1, cv=cv)\n",
    "grid.fit(X_train, np.ravel(y_train, order='C'))\n",
    "print(grid.best_params_)\n",
    "pickle.dump(grid.best_estimator_, open('svm_clf', 'wb'))\n",
    "y_pred = grid.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 15 folds for each of 36 candidates, totalling 540 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/majed/my_partition/venv/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "360 fits failed out of a total of 540.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "180 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/majed/my_partition/venv/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/media/majed/my_partition/venv/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/media/majed/my_partition/venv/lib/python3.8/site-packages/xgboost/sklearn.py\", line 1516, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/media/majed/my_partition/venv/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/media/majed/my_partition/venv/lib/python3.8/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/media/majed/my_partition/venv/lib/python3.8/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/media/majed/my_partition/venv/lib/python3.8/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 2 for Parameter colsample_bylevel exceed bound [0,1]\n",
      "colsample_bylevel: Subsample ratio of columns, resample on each level.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "180 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/majed/my_partition/venv/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/media/majed/my_partition/venv/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/media/majed/my_partition/venv/lib/python3.8/site-packages/xgboost/sklearn.py\", line 1516, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/media/majed/my_partition/venv/lib/python3.8/site-packages/xgboost/core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/media/majed/my_partition/venv/lib/python3.8/site-packages/xgboost/training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/media/majed/my_partition/venv/lib/python3.8/site-packages/xgboost/core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"/media/majed/my_partition/venv/lib/python3.8/site-packages/xgboost/core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 3 for Parameter colsample_bylevel exceed bound [0,1]\n",
      "colsample_bylevel: Subsample ratio of columns, resample on each level.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/media/majed/my_partition/venv/lib/python3.8/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.94041667 0.94125    0.94416667        nan        nan        nan\n",
      "        nan        nan        nan 0.94041667 0.94166667 0.94416667\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.94041667 0.94166667 0.94416667        nan        nan        nan\n",
      "        nan        nan        nan 0.94041667 0.94166667 0.94416667\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'base_score': 0.5, 'colsample_bylevel': 1, 'max_depth': 5}\n",
      "0.94\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "model = XGBClassifier(n_estimators=1000, max_depth=7, eta=0.1, subsample=0.7, colsample_bytree=0.8)\n",
    "\n",
    "param_grid = {\n",
    "    'base_score': [0.5, 1, 1.5, 2], \n",
    "    'max_depth': [3, 4, 5],\n",
    "    'colsample_bylevel': [1, 2, 3]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(model, param_grid, refit = True, verbose = 1,n_jobs=-1, cv=cv)\n",
    "grid.fit(X_train, np.ravel(y_train, order='C'))\n",
    "print(grid.best_params_)\n",
    "pickle.dump(grid.best_estimator_, open('xgb_clf', 'wb'))\n",
    "y_pred = grid.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "61791c176976d1dba33a88a8a27a02f11bc2b338382ecaeae452ea430b08bb75"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
